{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25754c9b-bc6e-4994-a2f3-b24443bc1b99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🎯 **Objetivo do Notebook**\n",
    "\n",
    "Este notebook tem como objetivo demonstrar a construção de um **Stream Pipeline** utilizando o **Apache Spark Streaming** no ambiente do **Databricks**. O pipeline será desenvolvido com foco em:\n",
    "\n",
    "1. **Ingestão de dados em tempo real**: Utilizaremos a **OpenWeatherMap API** como fonte de dados, capturando dados meteorológicos em tempo real.\n",
    "2. **Filtragem dos dados**: Aplicaremos um filtro para selecionar apenas os dados relevantes, como temperaturas acima de um determinado valor.\n",
    "3. **Agregação dos dados**: Utilizaremos uma função de janela (*window*) para agregar os dados em intervalos de tempo definidos.\n",
    "4. **Output dos dados**: Os dados processados serão salvos em formato **Parquet**, um formato colunar otimizado para big data.\n",
    "5. **Deploy do pipeline**: Ao final, discutiremos como fazer o deploy desse pipeline em um ambiente de produção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81b72a8c-887f-47bb-bff0-cc4f2cc01daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🛠️ **Configuração do Ambiente**\n",
    "\n",
    "Vamos configurar o ambiente para utilizar o **Apache Spark**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e950f31d-5ee0-4911-ad0e-72d477df4d5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: pyspark in /local_disk0/.ephemeral_nfs/envs/pythonEnv-927d0361-6c0b-434f-be6c-91f3b2d13f74/lib/python3.9/site-packages (3.5.4)\nRequirement already satisfied: py4j==0.10.9.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-927d0361-6c0b-434f-be6c-91f3b2d13f74/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "319e8c84-b9d3-41c7-bede-62baff5119db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c5390c7-318c-4bb2-a108-6256dc45fd59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, avg, countDistinct, when, max, last, row_number\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, ArrayType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89ea8e37-e861-4aac-8391-767741f9644a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 🛠️ **Configuração da OpenWeatherMap API**\n",
    "\n",
    "Neste passo, vamos configurar a **OpenWeatherMap API** para capturar dados meteorológicos em tempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdcd9d9d-bea8-457e-a8df-ab1d38bacd97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkStreamingExample\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "727b9f2f-9d87-4179-9a01-fc74878400b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 Clima em Belem:\n🌡️ Temperatura: 29.02°C\n🌤️ Condição: scattered clouds\n🌍 Clima em Belo Horizonte:\n🌡️ Temperatura: 30.44°C\n🌤️ Condição: clear sky\n🌍 Clima em Brasilia:\n🌡️ Temperatura: 30.51°C\n🌤️ Condição: clear sky\n🌍 Clima em Curitiba:\n🌡️ Temperatura: 24.5°C\n🌤️ Condição: scattered clouds\n🌍 Clima em Fortaleza:\n🌡️ Temperatura: 28.07°C\n🌤️ Condição: few clouds\n🌍 Clima em Manaus:\n🌡️ Temperatura: 26.27°C\n🌤️ Condição: heavy intensity rain\n🌍 Clima em Porto Alegre:\n🌡️ Temperatura: 30.53°C\n🌤️ Condição: few clouds\n🌍 Clima em Recife:\n🌡️ Temperatura: 29.02°C\n🌤️ Condição: scattered clouds\n🌍 Clima em Rio de Janeiro:\n🌡️ Temperatura: 29.08°C\n🌤️ Condição: few clouds\n🌍 Clima em Salvador:\n🌡️ Temperatura: 28.98°C\n🌤️ Condição: clear sky\n🌍 Clima em Sao Paulo:\n🌡️ Temperatura: 25.72°C\n🌤️ Condição: scattered clouds\n"
     ]
    }
   ],
   "source": [
    "# 🔑 Chave da API OpenWeatherMap\n",
    "API_KEY = \"585b0ba17238ebcef6c63abdabbaf94f\"\n",
    "\n",
    "# 📍 Lista de cidades do Brasil\n",
    "cidades = [\n",
    "    \"Belem\", \"Belo Horizonte\", \"Brasilia\", \"Curitiba\", \"Fortaleza\",\n",
    "    \"Manaus\", \"Porto Alegre\", \"Recife\", \"Rio de Janeiro\", \"Salvador\", \"Sao Paulo\"\n",
    "]\n",
    "\n",
    "# 🌍 País\n",
    "pais = \"BR\"\n",
    "\n",
    "# 🔄 Fazer requisições para cada cidade\n",
    "for cidade in cidades:\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={cidade},{pais}&appid={API_KEY}&units=metric\"\n",
    "\n",
    "    # 🚀 Fazer a requisição\n",
    "    response = requests.get(url)\n",
    "    dados = response.json()\n",
    "\n",
    "    # 📊 Exibir os dados\n",
    "    if dados[\"cod\"] == 200:\n",
    "        print(f\"🌍 Clima em {cidade}:\")\n",
    "        print(f\"🌡️ Temperatura: {dados['main']['temp']}°C\")\n",
    "        print(f\"🌤️ Condição: {dados['weather'][0]['description']}\")\n",
    "    else:\n",
    "        print(f\"❌ Erro ao buscar dados para: {cidade}\")\n",
    "\n",
    "    # ⏳ Aguardar 1 segundo para evitar sobrecarga na API\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0abd98f1-11a2-4638-bd71-ebaadbb0a36e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Criar um Diretório para Armazenar os Arquivos JSON\n",
    "\n",
    "Neste passo, criamos um diretório (`/FileStore/weather_data`) onde vamos armazenar os arquivos JSON que simulam um fluxo contínuo de dados meteorológicos.  \n",
    "Este diretório será utilizado como fonte de dados para o Spark Streaming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd2ec8f-2f3c-43c3-ac9c-4239f48a7303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Diretório criado: /FileStore/weather_data\nWrote 577 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Belem_1740171583.json\nWrote 571 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Belo_Horizonte_1740171584.json\nWrote 571 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Brasilia_1740171585.json\nWrote 574 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Curitiba_1740171586.json\nWrote 569 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Fortaleza_1740171587.json\nWrote 596 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Manaus_1740171588.json\nWrote 575 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Porto_Alegre_1740171589.json\nWrote 572 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Recife_1740171590.json\nWrote 573 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Rio_de_Janeiro_1740171592.json\nWrote 581 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Salvador_1740171593.json\nWrote 580 bytes.\n✅ Dados salvos: /FileStore/weather_data/weather_Sao_Paulo_1740171594.json\n📂 Arquivos JSON na pasta:\nOut[4]: [FileInfo(path='dbfs:/FileStore/weather_data/weather_Belem_1740170461.json', name='weather_Belem_1740170461.json', size=577, modificationTime=1740170462000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Belem_1740171583.json', name='weather_Belem_1740171583.json', size=577, modificationTime=1740171584000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Belo_Horizonte_1740170462.json', name='weather_Belo_Horizonte_1740170462.json', size=571, modificationTime=1740170463000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Belo_Horizonte_1740171584.json', name='weather_Belo_Horizonte_1740171584.json', size=571, modificationTime=1740171585000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Brasilia_1740170463.json', name='weather_Brasilia_1740170463.json', size=571, modificationTime=1740170464000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Brasilia_1740171585.json', name='weather_Brasilia_1740171585.json', size=571, modificationTime=1740171586000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Curitiba_1740170464.json', name='weather_Curitiba_1740170464.json', size=575, modificationTime=1740170465000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Curitiba_1740171586.json', name='weather_Curitiba_1740171586.json', size=574, modificationTime=1740171587000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Fortaleza_1740170465.json', name='weather_Fortaleza_1740170465.json', size=569, modificationTime=1740170466000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Fortaleza_1740171587.json', name='weather_Fortaleza_1740171587.json', size=569, modificationTime=1740171588000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Manaus_1740170466.json', name='weather_Manaus_1740170466.json', size=596, modificationTime=1740170467000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Manaus_1740171588.json', name='weather_Manaus_1740171588.json', size=596, modificationTime=1740171589000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Porto_Alegre_1740170468.json', name='weather_Porto_Alegre_1740170468.json', size=575, modificationTime=1740170469000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Porto_Alegre_1740171589.json', name='weather_Porto_Alegre_1740171589.json', size=575, modificationTime=1740171590000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Recife_1740170469.json', name='weather_Recife_1740170469.json', size=572, modificationTime=1740170470000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Recife_1740171590.json', name='weather_Recife_1740171590.json', size=572, modificationTime=1740171592000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Rio_de_Janeiro_1740170470.json', name='weather_Rio_de_Janeiro_1740170470.json', size=573, modificationTime=1740170471000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Rio_de_Janeiro_1740171592.json', name='weather_Rio_de_Janeiro_1740171592.json', size=573, modificationTime=1740171593000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Salvador_1740170471.json', name='weather_Salvador_1740170471.json', size=581, modificationTime=1740170472000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Salvador_1740171593.json', name='weather_Salvador_1740171593.json', size=581, modificationTime=1740171594000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Sao_Paulo_1740170472.json', name='weather_Sao_Paulo_1740170472.json', size=580, modificationTime=1740170473000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Sao_Paulo_1740171594.json', name='weather_Sao_Paulo_1740171594.json', size=580, modificationTime=1740171595000)]"
     ]
    }
   ],
   "source": [
    "# 📂 Caminho fixo para salvar os arquivos JSON no FileStore\n",
    "input_dir = \"/FileStore/weather_data\"\n",
    "\n",
    "# 🛠 Criar o diretório se não existir\n",
    "dbutils.fs.mkdirs(input_dir)\n",
    "\n",
    "print(f\"📁 Diretório criado: {input_dir}\")\n",
    "\n",
    "def salvar_dados_json(cidade):\n",
    "    # 📡 URL da API para a cidade atual\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={cidade},BR&appid={API_KEY}&units=metric\"\n",
    "    \n",
    "    # 🌍 Consulta a API OpenWeatherMap\n",
    "    response = requests.get(url)\n",
    "    dados = response.json()\n",
    "\n",
    "    if dados[\"cod\"] == 200:\n",
    "        # 📄 Define o nome do arquivo com a cidade + timestamp\n",
    "        file_path = f\"{input_dir}/weather_{cidade.replace(' ', '_')}_{int(time.time())}.json\"\n",
    "\n",
    "        # 💾 Salva os dados no formato JSON usando dbutils.fs.put()\n",
    "        dbutils.fs.put(file_path, json.dumps(dados), overwrite=False)\n",
    "\n",
    "        print(f\"✅ Dados salvos: {file_path}\")\n",
    "    else:\n",
    "        print(f\"❌ Cidade não encontrada: {cidade}\")\n",
    "\n",
    "# 🔄 Gerar arquivos JSON para todas as cidades\n",
    "for cidade in cidades:\n",
    "    salvar_dados_json(cidade)\n",
    "    time.sleep(1)  # ⏳ Pequeno intervalo para evitar sobrecarga na API\n",
    "\n",
    "# 🔍 Verificar se os arquivos foram salvos\n",
    "print(\"📂 Arquivos JSON na pasta:\")\n",
    "dbutils.fs.ls(input_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7199567-e329-41e9-a39b-538e049c4603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Ler os Arquivos JSON com Spark Streaming\n",
    "\n",
    "Agora que temos um fluxo contínuo de arquivos JSON sendo gerado no diretório `/FileStore/weather_data`, vamos configurar o **Spark Structured Streaming** para:\n",
    "\n",
    "- Monitorar esse diretório em tempo real.\n",
    "- Ler os arquivos JSON assim que forem criados.\n",
    "- Converter os dados para um **DataFrame de Streaming**.\n",
    "\n",
    "Isso nos permitirá processar os dados dinamicamente à medida que novos arquivos forem adicionados. 🚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b88ce9e2-ce29-4231-9825-9bc72be8cb1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dados processados:\n+--------------+-------+--------------------+\n|name          |main   |weather_description |\n+--------------+-------+--------------------+\n|Manaus        |{26.27}|heavy intensity rain|\n|Manaus        |{26.27}|heavy intensity rain|\n|Salvador      |{28.98}|clear sky           |\n|Salvador      |{28.98}|clear sky           |\n|São Paulo     |{25.89}|scattered clouds    |\n|São Paulo     |{25.72}|scattered clouds    |\n|Belém         |{29.02}|scattered clouds    |\n|Belém         |{29.02}|scattered clouds    |\n|Curitiba      |{25.03}|scattered clouds    |\n|Porto Alegre  |{30.93}|few clouds          |\n|Porto Alegre  |{30.53}|few clouds          |\n|Curitiba      |{24.5} |scattered clouds    |\n|Rio de Janeiro|{29.08}|few clouds          |\n|Rio de Janeiro|{29.08}|few clouds          |\n|Recife        |{29.02}|scattered clouds    |\n|Recife        |{29.02}|scattered clouds    |\n|Belo Horizonte|{30.44}|clear sky           |\n|Belo Horizonte|{30.44}|clear sky           |\n|Brasília      |{30.51}|clear sky           |\n|Brasília      |{30.51}|clear sky           |\n+--------------+-------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 📌 Definir o esquema corrigido do JSON\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),  # Nome da cidade\n",
    "    StructField(\"main\", StructType([\n",
    "        StructField(\"temp\", DoubleType(), True)  # Temperatura em Celsius\n",
    "    ]), True),\n",
    "    StructField(\"weather\", ArrayType(StructType([  # Ajustado para ser uma lista de Structs\n",
    "        StructField(\"description\", StringType(), True)\n",
    "    ])), True)\n",
    "])\n",
    "\n",
    "# 📂 Caminho do diretório dos arquivos JSON\n",
    "input_dir = \"/FileStore/weather_data\"\n",
    "\n",
    "# 📝 Ler os arquivos JSON como DataFrame\n",
    "df = spark.read.schema(schema).json(input_dir)\n",
    "\n",
    "# 📌 Extrair corretamente a descrição do clima (primeiro item do array)\n",
    "df = df.withColumn(\"weather_description\", expr(\"weather[0].description\")).drop(\"weather\")\n",
    "\n",
    "# 📊 Exibir os dados processados\n",
    "print(\"📊 Dados processados:\")\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d09d53d5-f064-4295-b3b7-c0b3d9f8692c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Aplicar Filtros e Agregações\n",
    "Agora que os dados estão sendo processados, vamos:\n",
    "- **Filtrar apenas temperaturas acima de 25°C**.\n",
    "- **Calcular a média de temperatura das últimas medições**.\n",
    "- **Salvar o resultado final no formato Parquet**.\n",
    "\n",
    "Essas transformações permitirão analisar melhor os dados capturados. 🚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71659418-2b18-47fd-9130-d4511547d4c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dados após filtro (temperatura > 25°C):\n+--------------+-------+--------------------+\n|name          |main   |weather_description |\n+--------------+-------+--------------------+\n|Manaus        |{26.27}|heavy intensity rain|\n|Manaus        |{26.27}|heavy intensity rain|\n|Salvador      |{28.98}|clear sky           |\n|Salvador      |{28.98}|clear sky           |\n|São Paulo     |{25.89}|scattered clouds    |\n|São Paulo     |{25.72}|scattered clouds    |\n|Belém         |{29.02}|scattered clouds    |\n|Belém         |{29.02}|scattered clouds    |\n|Curitiba      |{25.03}|scattered clouds    |\n|Porto Alegre  |{30.93}|few clouds          |\n|Porto Alegre  |{30.53}|few clouds          |\n|Rio de Janeiro|{29.08}|few clouds          |\n|Rio de Janeiro|{29.08}|few clouds          |\n|Recife        |{29.02}|scattered clouds    |\n|Recife        |{29.02}|scattered clouds    |\n|Belo Horizonte|{30.44}|clear sky           |\n|Belo Horizonte|{30.44}|clear sky           |\n|Brasília      |{30.51}|clear sky           |\n|Brasília      |{30.51}|clear sky           |\n|Fortaleza     |{29.07}|few clouds          |\n+--------------+-------+--------------------+\nonly showing top 20 rows\n\n📊 Temperatura média por cidade:\n+--------------+--------+\n|name          |avg_temp|\n+--------------+--------+\n|Salvador      |28.98   |\n|Manaus        |26.27   |\n|São Paulo     |25.805  |\n|Curitiba      |25.03   |\n|Belém         |29.02   |\n|Porto Alegre  |30.73   |\n|Recife        |29.02   |\n|Rio de Janeiro|29.08   |\n|Belo Horizonte|30.44   |\n|Fortaleza     |28.57   |\n|Brasília      |30.51   |\n+--------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# 🔹 **Aplicar um filtro**: Somente cidades com temperatura acima de 25°C\n",
    "df_filtrado = df.filter(col(\"main.temp\") > 25)\n",
    "\n",
    "# 📊 Mostrar os dados após o filtro\n",
    "print(\"📊 Dados após filtro (temperatura > 25°C):\")\n",
    "df_filtrado.show(truncate=False)\n",
    "\n",
    "# 🔹 **Aplicar uma agregação**: Calcular a média da temperatura por cidade\n",
    "df_aggregado = df_filtrado.groupBy(\"name\").agg(avg(col(\"main.temp\")).alias(\"avg_temp\"))\n",
    "\n",
    "# 📊 Mostrar os dados agregados\n",
    "print(\"📊 Temperatura média por cidade:\")\n",
    "df_aggregado.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb79372-6478-4d48-8787-08ca80ddbb02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Classificação da Temperatura\n",
    "Agora, vamos **criar uma nova coluna** chamada **`temperature_category`**, que classifica as temperaturas em categorias com base na seguinte lógica:\n",
    "\n",
    "| Temperatura (`temp`) | Categoria              |\n",
    "|----------------------|------------------------|\n",
    "| Menos de 15°C       | 🧊 **Frio**            |\n",
    "| Entre 15°C e 25°C   | 🌤️ **Agradável**      |\n",
    "| Acima de 25°C       | 🔥 **Quente**          |\n",
    "\n",
    "Isso ajudará a entender melhor a distribuição das temperaturas e facilitará futuras análises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae81bc1-e6db-4132-815e-dce11b306376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dados categorizados:\n+--------------+-------+--------------------+--------------------+\n|name          |main   |weather_description |temperature_category|\n+--------------+-------+--------------------+--------------------+\n|Manaus        |{26.27}|heavy intensity rain|Quente              |\n|Manaus        |{26.27}|heavy intensity rain|Quente              |\n|Salvador      |{28.98}|clear sky           |Quente              |\n|Salvador      |{28.98}|clear sky           |Quente              |\n|São Paulo     |{25.89}|scattered clouds    |Quente              |\n|São Paulo     |{25.72}|scattered clouds    |Quente              |\n|Belém         |{29.02}|scattered clouds    |Quente              |\n|Belém         |{29.02}|scattered clouds    |Quente              |\n|Curitiba      |{25.03}|scattered clouds    |Quente              |\n|Porto Alegre  |{30.93}|few clouds          |Quente              |\n|Porto Alegre  |{30.53}|few clouds          |Quente              |\n|Rio de Janeiro|{29.08}|few clouds          |Quente              |\n|Rio de Janeiro|{29.08}|few clouds          |Quente              |\n|Recife        |{29.02}|scattered clouds    |Quente              |\n|Recife        |{29.02}|scattered clouds    |Quente              |\n|Belo Horizonte|{30.44}|clear sky           |Quente              |\n|Belo Horizonte|{30.44}|clear sky           |Quente              |\n|Brasília      |{30.51}|clear sky           |Quente              |\n|Brasília      |{30.51}|clear sky           |Quente              |\n|Fortaleza     |{29.07}|few clouds          |Quente              |\n+--------------+-------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 🔹 **Criar uma nova coluna 'temperature_category'**\n",
    "df_categorizado = df_filtrado.withColumn(\n",
    "    \"temperature_category\",\n",
    "    when(col(\"main.temp\") < 15, \"Frio\")\n",
    "    .when((col(\"main.temp\") >= 15) & (col(\"main.temp\") <= 25), \"Agradável\")\n",
    "    .otherwise(\"Quente\")\n",
    ")\n",
    "\n",
    "# 📊 Exibir os dados com a nova categoria de temperatura\n",
    "print(\"📊 Dados categorizados:\")\n",
    "df_categorizado.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f1c31be-ddb0-4bbf-9485-b93962c52684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Contagem de Cidades por Categoria de Temperatura\n",
    "Agora que categorizamos as temperaturas, vamos **contar quantas cidades pertencem a cada categoria** (`Frio`, `Agradável`, `Quente`).\n",
    "\n",
    "Isso nos permite entender **como a temperatura está distribuída entre as cidades** e identificar tendências climáticas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c7e798d-34b2-428c-ba96-0253b3c8b6d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Quantidade de cidades distintas por categoria de temperatura:\n+--------------------+------------+\n|temperature_category|total_cities|\n+--------------------+------------+\n|Quente              |11          |\n+--------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 🔹 **Contar cidades distintas em cada categoria de temperatura**\n",
    "df_contagem = df_categorizado.groupBy(\"temperature_category\").agg(countDistinct(\"name\").alias(\"total_cities\"))\n",
    "\n",
    "# 📊 Exibir os resultados ordenados por categoria\n",
    "print(\"📊 Quantidade de cidades distintas por categoria de temperatura:\")\n",
    "df_contagem.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6fc1848-5582-47fe-a977-c685fb0fd154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Ranking das Cidades Mais Quentes\n",
    "Agora, vamos criar um **ranking das cidades com as temperaturas mais altas**, ordenando os dados da **maior para a menor temperatura**.\n",
    "\n",
    "Isso nos ajudará a identificar **quais cidades estão enfrentando as temperaturas mais elevadas** no momento da análise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62b5ea7a-5f96-4dff-bdef-fa30dd72de4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Top 5 Cidades Mais Quentes:\n+-------+--------------+--------+\n|ranking|name          |max_temp|\n+-------+--------------+--------+\n|1      |Porto Alegre  |30.93   |\n|2      |Brasília      |30.51   |\n|3      |Belo Horizonte|30.44   |\n|4      |Rio de Janeiro|29.08   |\n|5      |Fortaleza     |29.07   |\n+-------+--------------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 🔹 **Selecionar a maior temperatura registrada para cada cidade**\n",
    "df_ranking = df_categorizado.groupBy(\"name\").agg(\n",
    "    max(\"main.temp\").alias(\"max_temp\")  # Pegando a maior temperatura registrada por cidade\n",
    ")\n",
    "\n",
    "# 🔹 **Criar a posição no ranking**\n",
    "window_spec = Window.orderBy(col(\"max_temp\").desc())\n",
    "df_ranking = df_ranking.withColumn(\"ranking\", row_number().over(window_spec))\n",
    "\n",
    "# 📊 Exibir o Top 5 das cidades mais quentes\n",
    "print(\"📊 Top 5 Cidades Mais Quentes:\")\n",
    "df_ranking.select(\"ranking\", \"name\", \"max_temp\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71005b4a-1e18-4076-9c12-8692116654a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Cálculo da Média Móvel da Temperatura\n",
    "Agora, vamos calcular uma **média móvel da temperatura** para cada cidade, considerando os últimos **3 registros**.\n",
    "\n",
    "Isso ajudará a suavizar variações e entender **a tendência de temperatura ao longo do tempo**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc73c722-05cf-40cc-ad0a-515b17989a9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Média Móvel Final por Cidade:\n+--------------+------------------+\n|name          |avg_temp_3_records|\n+--------------+------------------+\n|Belo Horizonte|30.44             |\n|Belém         |29.02             |\n|Brasília      |30.51             |\n|Curitiba      |25.03             |\n|Fortaleza     |28.57             |\n|Manaus        |26.27             |\n|Porto Alegre  |30.73             |\n|Recife        |29.02             |\n|Rio de Janeiro|29.08             |\n|Salvador      |28.98             |\n|São Paulo     |25.805            |\n+--------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Criar um ID incremental para simular timestamps diferentes\n",
    "df_temporal = df_categorizado.withColumn(\"timestamp\", expr(\"current_timestamp() + interval 10 seconds * (monotonically_increasing_id() % 5)\"))\n",
    "\n",
    "# 🔹 Criar uma janela de tempo para calcular a média móvel considerando os últimos 3 registros\n",
    "window_spec = Window.partitionBy(\"name\").orderBy(col(\"timestamp\")).rowsBetween(-2, 0)\n",
    "\n",
    "# 🔹 Calcular a média móvel da temperatura\n",
    "df_media_movel = df_temporal.withColumn(\"avg_temp_3_records\", avg(\"main.temp\").over(window_spec))\n",
    "\n",
    "# 🔹 Selecionar apenas a última média móvel calculada para cada cidade\n",
    "df_final = df_media_movel.groupBy(\"name\").agg(last(\"avg_temp_3_records\").alias(\"avg_temp_3_records\"))\n",
    "\n",
    "# 📊 Exibir o resultado final (um único registro por cidade)\n",
    "print(\"📊 Média Móvel Final por Cidade:\")\n",
    "df_final.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0236e4d6-bbf4-4210-ab24-d54088a54e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Diferença entre Temperatura Atual e Média Móvel\n",
    "Agora, vamos calcular a **diferença entre a temperatura mais recente de cada cidade e a média móvel**.\n",
    "\n",
    "Isso nos ajudará a entender **se a temperatura está subindo ou caindo** em relação à tendência recente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62db5aee-6e33-4ae7-8fbb-11a08695d89d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Diferença entre Temperatura Atual e Média Móvel:\n+--------------+-----------+------------------+-------------------+\n|name          |latest_temp|avg_temp_3_records|temp_variation     |\n+--------------+-----------+------------------+-------------------+\n|Belo Horizonte|30.44      |30.44             |0.0                |\n|Belém         |29.02      |29.02             |0.0                |\n|Brasília      |30.51      |30.51             |0.0                |\n|Curitiba      |25.03      |25.03             |0.0                |\n|Fortaleza     |29.07      |28.57             |0.5                |\n|Manaus        |26.27      |26.27             |0.0                |\n|Porto Alegre  |30.93      |30.73             |0.1999999999999993 |\n|Recife        |29.02      |29.02             |0.0                |\n|Rio de Janeiro|29.08      |29.08             |0.0                |\n|Salvador      |28.98      |28.98             |0.0                |\n|São Paulo     |25.89      |25.805            |0.08500000000000085|\n+--------------+-----------+------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Pegar a temperatura mais recente para cada cidade\n",
    "df_temp_recente = df_temporal.groupBy(\"name\").agg(\n",
    "    max(\"main.temp\").alias(\"latest_temp\")  # Última temperatura registrada\n",
    ")\n",
    "\n",
    "# 🔹 Juntar com a média móvel final\n",
    "df_com_diferenca = df_temp_recente.join(df_final, \"name\", \"inner\") \\\n",
    "    .withColumn(\"temp_variation\", col(\"latest_temp\") - col(\"avg_temp_3_records\"))\n",
    "\n",
    "# 📊 Exibir os resultados finais\n",
    "print(\"📊 Diferença entre Temperatura Atual e Média Móvel:\")\n",
    "df_com_diferenca.select(\"name\", \"latest_temp\", \"avg_temp_3_records\", \"temp_variation\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6d232cf-d7ec-429c-b0b9-9221e39a5598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Passo Final: Exportação dos Dados Processados\n",
    "Agora, vamos **salvar os dados finais** para que possam ser usados posteriormente.  \n",
    "Os arquivos serão exportados nos seguintes formatos:\n",
    "- 🗂 **Parquet** (`.parquet`) → Compactado e otimizado para Big Data\n",
    "- 📄 **CSV** (`.csv`) → Fácil de visualizar e compartilhar\n",
    "- 📜 **JSON** (`.json`) → Bom para integração com APIs\n",
    "\n",
    "Isso garante que os dados estejam prontos para serem consumidos por outras aplicações e análises futuras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "893f3b74-96a5-417c-816d-757f70e4f7a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados salvos em Parquet: dbfs:/FileStore/weather_final.parquet\n✅ Dados salvos em CSV: dbfs:/FileStore/weather_final.csv\n✅ Dados salvos em JSON: dbfs:/FileStore/weather_final.json\n"
     ]
    }
   ],
   "source": [
    "# 📂 Diretório onde os arquivos serão salvos\n",
    "output_path_parquet = \"dbfs:/FileStore/weather_final.parquet\"\n",
    "output_path_csv = \"dbfs:/FileStore/weather_final.csv\"\n",
    "output_path_json = \"dbfs:/FileStore/weather_final.json\"\n",
    "\n",
    "# 🗑️ Deletar arquivos antigos antes de salvar os novos\n",
    "dbutils.fs.rm(output_path_parquet, recurse=True)\n",
    "dbutils.fs.rm(output_path_csv, recurse=True)\n",
    "dbutils.fs.rm(output_path_json, recurse=True)\n",
    "\n",
    "# 💾 Salvar os dados finais em Parquet\n",
    "df_com_diferenca.write.mode(\"overwrite\").parquet(output_path_parquet)\n",
    "print(f\"✅ Dados salvos em Parquet: {output_path_parquet}\")\n",
    "\n",
    "# 💾 Salvar os dados finais em CSV\n",
    "df_com_diferenca.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path_csv)\n",
    "print(f\"✅ Dados salvos em CSV: {output_path_csv}\")\n",
    "\n",
    "# 💾 Salvar os dados finais em JSON\n",
    "df_com_diferenca.write.mode(\"overwrite\").json(output_path_json)\n",
    "print(f\"✅ Dados salvos em JSON: {output_path_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bb7e020-ecf9-4c31-80dc-bb7760c58a10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 📌 Deploy do Pipeline no Databricks\n",
    "Agora, vamos configurar a **execução automática** do pipeline, garantindo que os dados sejam processados e salvos sem intervenção manual.\n",
    "\n",
    "### **📌 Como funciona?**\n",
    "- Criamos um **Job no Databricks** para rodar automaticamente.\n",
    "- Configuramos um **agendamento** (a cada 1 hora).\n",
    "- O Job roda nosso **Notebook de Pipeline**, garantindo que os dados estejam sempre atualizados.\n",
    "\n",
    "Isso permite **automatizar o processamento**, tornando o pipeline **mais eficiente e escalável**! 🚀\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Clima",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
