{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25754c9b-bc6e-4994-a2f3-b24443bc1b99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ğŸ¯ **Objetivo do Notebook**\n",
    "\n",
    "Este notebook tem como objetivo demonstrar a construÃ§Ã£o de um **Stream Pipeline** utilizando o **Apache Spark Streaming** no ambiente do **Databricks**. O pipeline serÃ¡ desenvolvido com foco em:\n",
    "\n",
    "1. **IngestÃ£o de dados em tempo real**: Utilizaremos a **OpenWeatherMap API** como fonte de dados, capturando dados meteorolÃ³gicos em tempo real.\n",
    "2. **Filtragem dos dados**: Aplicaremos um filtro para selecionar apenas os dados relevantes, como temperaturas acima de um determinado valor.\n",
    "3. **AgregaÃ§Ã£o dos dados**: Utilizaremos uma funÃ§Ã£o de janela (*window*) para agregar os dados em intervalos de tempo definidos.\n",
    "4. **Output dos dados**: Os dados processados serÃ£o salvos em formato **Parquet**, um formato colunar otimizado para big data.\n",
    "5. **Deploy do pipeline**: Ao final, discutiremos como fazer o deploy desse pipeline em um ambiente de produÃ§Ã£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81b72a8c-887f-47bb-bff0-cc4f2cc01daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ğŸ› ï¸ **ConfiguraÃ§Ã£o do Ambiente**\n",
    "\n",
    "Vamos configurar o ambiente para utilizar o **Apache Spark**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e950f31d-5ee0-4911-ad0e-72d477df4d5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: pyspark in /local_disk0/.ephemeral_nfs/envs/pythonEnv-927d0361-6c0b-434f-be6c-91f3b2d13f74/lib/python3.9/site-packages (3.5.4)\nRequirement already satisfied: py4j==0.10.9.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-927d0361-6c0b-434f-be6c-91f3b2d13f74/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "319e8c84-b9d3-41c7-bede-62baff5119db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c5390c7-318c-4bb2-a108-6256dc45fd59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, avg, countDistinct, when, max, last, row_number\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, ArrayType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89ea8e37-e861-4aac-8391-767741f9644a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ğŸ› ï¸ **ConfiguraÃ§Ã£o da OpenWeatherMap API**\n",
    "\n",
    "Neste passo, vamos configurar a **OpenWeatherMap API** para capturar dados meteorolÃ³gicos em tempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdcd9d9d-bea8-457e-a8df-ab1d38bacd97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkStreamingExample\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "727b9f2f-9d87-4179-9a01-fc74878400b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Clima em Belem:\nğŸŒ¡ï¸ Temperatura: 29.02Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: scattered clouds\nğŸŒ Clima em Belo Horizonte:\nğŸŒ¡ï¸ Temperatura: 30.44Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: clear sky\nğŸŒ Clima em Brasilia:\nğŸŒ¡ï¸ Temperatura: 30.51Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: clear sky\nğŸŒ Clima em Curitiba:\nğŸŒ¡ï¸ Temperatura: 24.5Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: scattered clouds\nğŸŒ Clima em Fortaleza:\nğŸŒ¡ï¸ Temperatura: 28.07Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: few clouds\nğŸŒ Clima em Manaus:\nğŸŒ¡ï¸ Temperatura: 26.27Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: heavy intensity rain\nğŸŒ Clima em Porto Alegre:\nğŸŒ¡ï¸ Temperatura: 30.53Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: few clouds\nğŸŒ Clima em Recife:\nğŸŒ¡ï¸ Temperatura: 29.02Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: scattered clouds\nğŸŒ Clima em Rio de Janeiro:\nğŸŒ¡ï¸ Temperatura: 29.08Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: few clouds\nğŸŒ Clima em Salvador:\nğŸŒ¡ï¸ Temperatura: 28.98Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: clear sky\nğŸŒ Clima em Sao Paulo:\nğŸŒ¡ï¸ Temperatura: 25.72Â°C\nğŸŒ¤ï¸ CondiÃ§Ã£o: scattered clouds\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”‘ Chave da API OpenWeatherMap\n",
    "API_KEY = \"585b0ba17238ebcef6c63abdabbaf94f\"\n",
    "\n",
    "# ğŸ“ Lista de cidades do Brasil\n",
    "cidades = [\n",
    "    \"Belem\", \"Belo Horizonte\", \"Brasilia\", \"Curitiba\", \"Fortaleza\",\n",
    "    \"Manaus\", \"Porto Alegre\", \"Recife\", \"Rio de Janeiro\", \"Salvador\", \"Sao Paulo\"\n",
    "]\n",
    "\n",
    "# ğŸŒ PaÃ­s\n",
    "pais = \"BR\"\n",
    "\n",
    "# ğŸ”„ Fazer requisiÃ§Ãµes para cada cidade\n",
    "for cidade in cidades:\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={cidade},{pais}&appid={API_KEY}&units=metric\"\n",
    "\n",
    "    # ğŸš€ Fazer a requisiÃ§Ã£o\n",
    "    response = requests.get(url)\n",
    "    dados = response.json()\n",
    "\n",
    "    # ğŸ“Š Exibir os dados\n",
    "    if dados[\"cod\"] == 200:\n",
    "        print(f\"ğŸŒ Clima em {cidade}:\")\n",
    "        print(f\"ğŸŒ¡ï¸ Temperatura: {dados['main']['temp']}Â°C\")\n",
    "        print(f\"ğŸŒ¤ï¸ CondiÃ§Ã£o: {dados['weather'][0]['description']}\")\n",
    "    else:\n",
    "        print(f\"âŒ Erro ao buscar dados para: {cidade}\")\n",
    "\n",
    "    # â³ Aguardar 1 segundo para evitar sobrecarga na API\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0abd98f1-11a2-4638-bd71-ebaadbb0a36e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ Criar um DiretÃ³rio para Armazenar os Arquivos JSON\n",
    "\n",
    "Neste passo, criamos um diretÃ³rio (`/FileStore/weather_data`) onde vamos armazenar os arquivos JSON que simulam um fluxo contÃ­nuo de dados meteorolÃ³gicos.  \n",
    "Este diretÃ³rio serÃ¡ utilizado como fonte de dados para o Spark Streaming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd2ec8f-2f3c-43c3-ac9c-4239f48a7303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ DiretÃ³rio criado: /FileStore/weather_data\nWrote 577 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Belem_1740171583.json\nWrote 571 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Belo_Horizonte_1740171584.json\nWrote 571 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Brasilia_1740171585.json\nWrote 574 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Curitiba_1740171586.json\nWrote 569 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Fortaleza_1740171587.json\nWrote 596 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Manaus_1740171588.json\nWrote 575 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Porto_Alegre_1740171589.json\nWrote 572 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Recife_1740171590.json\nWrote 573 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Rio_de_Janeiro_1740171592.json\nWrote 581 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Salvador_1740171593.json\nWrote 580 bytes.\nâœ… Dados salvos: /FileStore/weather_data/weather_Sao_Paulo_1740171594.json\nğŸ“‚ Arquivos JSON na pasta:\nOut[4]: [FileInfo(path='dbfs:/FileStore/weather_data/weather_Belem_1740170461.json', name='weather_Belem_1740170461.json', size=577, modificationTime=1740170462000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Belem_1740171583.json', name='weather_Belem_1740171583.json', size=577, modificationTime=1740171584000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Belo_Horizonte_1740170462.json', name='weather_Belo_Horizonte_1740170462.json', size=571, modificationTime=1740170463000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Belo_Horizonte_1740171584.json', name='weather_Belo_Horizonte_1740171584.json', size=571, modificationTime=1740171585000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Brasilia_1740170463.json', name='weather_Brasilia_1740170463.json', size=571, modificationTime=1740170464000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Brasilia_1740171585.json', name='weather_Brasilia_1740171585.json', size=571, modificationTime=1740171586000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Curitiba_1740170464.json', name='weather_Curitiba_1740170464.json', size=575, modificationTime=1740170465000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Curitiba_1740171586.json', name='weather_Curitiba_1740171586.json', size=574, modificationTime=1740171587000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Fortaleza_1740170465.json', name='weather_Fortaleza_1740170465.json', size=569, modificationTime=1740170466000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Fortaleza_1740171587.json', name='weather_Fortaleza_1740171587.json', size=569, modificationTime=1740171588000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Manaus_1740170466.json', name='weather_Manaus_1740170466.json', size=596, modificationTime=1740170467000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Manaus_1740171588.json', name='weather_Manaus_1740171588.json', size=596, modificationTime=1740171589000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Porto_Alegre_1740170468.json', name='weather_Porto_Alegre_1740170468.json', size=575, modificationTime=1740170469000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Porto_Alegre_1740171589.json', name='weather_Porto_Alegre_1740171589.json', size=575, modificationTime=1740171590000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Recife_1740170469.json', name='weather_Recife_1740170469.json', size=572, modificationTime=1740170470000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Recife_1740171590.json', name='weather_Recife_1740171590.json', size=572, modificationTime=1740171592000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Rio_de_Janeiro_1740170470.json', name='weather_Rio_de_Janeiro_1740170470.json', size=573, modificationTime=1740170471000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Rio_de_Janeiro_1740171592.json', name='weather_Rio_de_Janeiro_1740171592.json', size=573, modificationTime=1740171593000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Salvador_1740170471.json', name='weather_Salvador_1740170471.json', size=581, modificationTime=1740170472000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Salvador_1740171593.json', name='weather_Salvador_1740171593.json', size=581, modificationTime=1740171594000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Sao_Paulo_1740170472.json', name='weather_Sao_Paulo_1740170472.json', size=580, modificationTime=1740170473000),\n FileInfo(path='dbfs:/FileStore/weather_data/weather_Sao_Paulo_1740171594.json', name='weather_Sao_Paulo_1740171594.json', size=580, modificationTime=1740171595000)]"
     ]
    }
   ],
   "source": [
    "# ğŸ“‚ Caminho fixo para salvar os arquivos JSON no FileStore\n",
    "input_dir = \"/FileStore/weather_data\"\n",
    "\n",
    "# ğŸ›  Criar o diretÃ³rio se nÃ£o existir\n",
    "dbutils.fs.mkdirs(input_dir)\n",
    "\n",
    "print(f\"ğŸ“ DiretÃ³rio criado: {input_dir}\")\n",
    "\n",
    "def salvar_dados_json(cidade):\n",
    "    # ğŸ“¡ URL da API para a cidade atual\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={cidade},BR&appid={API_KEY}&units=metric\"\n",
    "    \n",
    "    # ğŸŒ Consulta a API OpenWeatherMap\n",
    "    response = requests.get(url)\n",
    "    dados = response.json()\n",
    "\n",
    "    if dados[\"cod\"] == 200:\n",
    "        # ğŸ“„ Define o nome do arquivo com a cidade + timestamp\n",
    "        file_path = f\"{input_dir}/weather_{cidade.replace(' ', '_')}_{int(time.time())}.json\"\n",
    "\n",
    "        # ğŸ’¾ Salva os dados no formato JSON usando dbutils.fs.put()\n",
    "        dbutils.fs.put(file_path, json.dumps(dados), overwrite=False)\n",
    "\n",
    "        print(f\"âœ… Dados salvos: {file_path}\")\n",
    "    else:\n",
    "        print(f\"âŒ Cidade nÃ£o encontrada: {cidade}\")\n",
    "\n",
    "# ğŸ”„ Gerar arquivos JSON para todas as cidades\n",
    "for cidade in cidades:\n",
    "    salvar_dados_json(cidade)\n",
    "    time.sleep(1)  # â³ Pequeno intervalo para evitar sobrecarga na API\n",
    "\n",
    "# ğŸ” Verificar se os arquivos foram salvos\n",
    "print(\"ğŸ“‚ Arquivos JSON na pasta:\")\n",
    "dbutils.fs.ls(input_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7199567-e329-41e9-a39b-538e049c4603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ Ler os Arquivos JSON com Spark Streaming\n",
    "\n",
    "Agora que temos um fluxo contÃ­nuo de arquivos JSON sendo gerado no diretÃ³rio `/FileStore/weather_data`, vamos configurar o **Spark Structured Streaming** para:\n",
    "\n",
    "- Monitorar esse diretÃ³rio em tempo real.\n",
    "- Ler os arquivos JSON assim que forem criados.\n",
    "- Converter os dados para um **DataFrame de Streaming**.\n",
    "\n",
    "Isso nos permitirÃ¡ processar os dados dinamicamente Ã  medida que novos arquivos forem adicionados. ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b88ce9e2-ce29-4231-9825-9bc72be8cb1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dados processados:\n+--------------+-------+--------------------+\n|name          |main   |weather_description |\n+--------------+-------+--------------------+\n|Manaus        |{26.27}|heavy intensity rain|\n|Manaus        |{26.27}|heavy intensity rain|\n|Salvador      |{28.98}|clear sky           |\n|Salvador      |{28.98}|clear sky           |\n|SÃ£o Paulo     |{25.89}|scattered clouds    |\n|SÃ£o Paulo     |{25.72}|scattered clouds    |\n|BelÃ©m         |{29.02}|scattered clouds    |\n|BelÃ©m         |{29.02}|scattered clouds    |\n|Curitiba      |{25.03}|scattered clouds    |\n|Porto Alegre  |{30.93}|few clouds          |\n|Porto Alegre  |{30.53}|few clouds          |\n|Curitiba      |{24.5} |scattered clouds    |\n|Rio de Janeiro|{29.08}|few clouds          |\n|Rio de Janeiro|{29.08}|few clouds          |\n|Recife        |{29.02}|scattered clouds    |\n|Recife        |{29.02}|scattered clouds    |\n|Belo Horizonte|{30.44}|clear sky           |\n|Belo Horizonte|{30.44}|clear sky           |\n|BrasÃ­lia      |{30.51}|clear sky           |\n|BrasÃ­lia      |{30.51}|clear sky           |\n+--------------+-------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ Definir o esquema corrigido do JSON\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),  # Nome da cidade\n",
    "    StructField(\"main\", StructType([\n",
    "        StructField(\"temp\", DoubleType(), True)  # Temperatura em Celsius\n",
    "    ]), True),\n",
    "    StructField(\"weather\", ArrayType(StructType([  # Ajustado para ser uma lista de Structs\n",
    "        StructField(\"description\", StringType(), True)\n",
    "    ])), True)\n",
    "])\n",
    "\n",
    "# ğŸ“‚ Caminho do diretÃ³rio dos arquivos JSON\n",
    "input_dir = \"/FileStore/weather_data\"\n",
    "\n",
    "# ğŸ“ Ler os arquivos JSON como DataFrame\n",
    "df = spark.read.schema(schema).json(input_dir)\n",
    "\n",
    "# ğŸ“Œ Extrair corretamente a descriÃ§Ã£o do clima (primeiro item do array)\n",
    "df = df.withColumn(\"weather_description\", expr(\"weather[0].description\")).drop(\"weather\")\n",
    "\n",
    "# ğŸ“Š Exibir os dados processados\n",
    "print(\"ğŸ“Š Dados processados:\")\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d09d53d5-f064-4295-b3b7-c0b3d9f8692c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ Aplicar Filtros e AgregaÃ§Ãµes\n",
    "Agora que os dados estÃ£o sendo processados, vamos:\n",
    "- **Filtrar apenas temperaturas acima de 25Â°C**.\n",
    "- **Calcular a mÃ©dia de temperatura das Ãºltimas mediÃ§Ãµes**.\n",
    "- **Salvar o resultado final no formato Parquet**.\n",
    "\n",
    "Essas transformaÃ§Ãµes permitirÃ£o analisar melhor os dados capturados. ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71659418-2b18-47fd-9130-d4511547d4c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dados apÃ³s filtro (temperatura > 25Â°C):\n+--------------+-------+--------------------+\n|name          |main   |weather_description |\n+--------------+-------+--------------------+\n|Manaus        |{26.27}|heavy intensity rain|\n|Manaus        |{26.27}|heavy intensity rain|\n|Salvador      |{28.98}|clear sky           |\n|Salvador      |{28.98}|clear sky           |\n|SÃ£o Paulo     |{25.89}|scattered clouds    |\n|SÃ£o Paulo     |{25.72}|scattered clouds    |\n|BelÃ©m         |{29.02}|scattered clouds    |\n|BelÃ©m         |{29.02}|scattered clouds    |\n|Curitiba      |{25.03}|scattered clouds    |\n|Porto Alegre  |{30.93}|few clouds          |\n|Porto Alegre  |{30.53}|few clouds          |\n|Rio de Janeiro|{29.08}|few clouds          |\n|Rio de Janeiro|{29.08}|few clouds          |\n|Recife        |{29.02}|scattered clouds    |\n|Recife        |{29.02}|scattered clouds    |\n|Belo Horizonte|{30.44}|clear sky           |\n|Belo Horizonte|{30.44}|clear sky           |\n|BrasÃ­lia      |{30.51}|clear sky           |\n|BrasÃ­lia      |{30.51}|clear sky           |\n|Fortaleza     |{29.07}|few clouds          |\n+--------------+-------+--------------------+\nonly showing top 20 rows\n\nğŸ“Š Temperatura mÃ©dia por cidade:\n+--------------+--------+\n|name          |avg_temp|\n+--------------+--------+\n|Salvador      |28.98   |\n|Manaus        |26.27   |\n|SÃ£o Paulo     |25.805  |\n|Curitiba      |25.03   |\n|BelÃ©m         |29.02   |\n|Porto Alegre  |30.73   |\n|Recife        |29.02   |\n|Rio de Janeiro|29.08   |\n|Belo Horizonte|30.44   |\n|Fortaleza     |28.57   |\n|BrasÃ­lia      |30.51   |\n+--------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ **Aplicar um filtro**: Somente cidades com temperatura acima de 25Â°C\n",
    "df_filtrado = df.filter(col(\"main.temp\") > 25)\n",
    "\n",
    "# ğŸ“Š Mostrar os dados apÃ³s o filtro\n",
    "print(\"ğŸ“Š Dados apÃ³s filtro (temperatura > 25Â°C):\")\n",
    "df_filtrado.show(truncate=False)\n",
    "\n",
    "# ğŸ”¹ **Aplicar uma agregaÃ§Ã£o**: Calcular a mÃ©dia da temperatura por cidade\n",
    "df_aggregado = df_filtrado.groupBy(\"name\").agg(avg(col(\"main.temp\")).alias(\"avg_temp\"))\n",
    "\n",
    "# ğŸ“Š Mostrar os dados agregados\n",
    "print(\"ğŸ“Š Temperatura mÃ©dia por cidade:\")\n",
    "df_aggregado.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb79372-6478-4d48-8787-08ca80ddbb02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ ClassificaÃ§Ã£o da Temperatura\n",
    "Agora, vamos **criar uma nova coluna** chamada **`temperature_category`**, que classifica as temperaturas em categorias com base na seguinte lÃ³gica:\n",
    "\n",
    "| Temperatura (`temp`) | Categoria              |\n",
    "|----------------------|------------------------|\n",
    "| Menos de 15Â°C       | ğŸ§Š **Frio**            |\n",
    "| Entre 15Â°C e 25Â°C   | ğŸŒ¤ï¸ **AgradÃ¡vel**      |\n",
    "| Acima de 25Â°C       | ğŸ”¥ **Quente**          |\n",
    "\n",
    "Isso ajudarÃ¡ a entender melhor a distribuiÃ§Ã£o das temperaturas e facilitarÃ¡ futuras anÃ¡lises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae81bc1-e6db-4132-815e-dce11b306376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dados categorizados:\n+--------------+-------+--------------------+--------------------+\n|name          |main   |weather_description |temperature_category|\n+--------------+-------+--------------------+--------------------+\n|Manaus        |{26.27}|heavy intensity rain|Quente              |\n|Manaus        |{26.27}|heavy intensity rain|Quente              |\n|Salvador      |{28.98}|clear sky           |Quente              |\n|Salvador      |{28.98}|clear sky           |Quente              |\n|SÃ£o Paulo     |{25.89}|scattered clouds    |Quente              |\n|SÃ£o Paulo     |{25.72}|scattered clouds    |Quente              |\n|BelÃ©m         |{29.02}|scattered clouds    |Quente              |\n|BelÃ©m         |{29.02}|scattered clouds    |Quente              |\n|Curitiba      |{25.03}|scattered clouds    |Quente              |\n|Porto Alegre  |{30.93}|few clouds          |Quente              |\n|Porto Alegre  |{30.53}|few clouds          |Quente              |\n|Rio de Janeiro|{29.08}|few clouds          |Quente              |\n|Rio de Janeiro|{29.08}|few clouds          |Quente              |\n|Recife        |{29.02}|scattered clouds    |Quente              |\n|Recife        |{29.02}|scattered clouds    |Quente              |\n|Belo Horizonte|{30.44}|clear sky           |Quente              |\n|Belo Horizonte|{30.44}|clear sky           |Quente              |\n|BrasÃ­lia      |{30.51}|clear sky           |Quente              |\n|BrasÃ­lia      |{30.51}|clear sky           |Quente              |\n|Fortaleza     |{29.07}|few clouds          |Quente              |\n+--------------+-------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ **Criar uma nova coluna 'temperature_category'**\n",
    "df_categorizado = df_filtrado.withColumn(\n",
    "    \"temperature_category\",\n",
    "    when(col(\"main.temp\") < 15, \"Frio\")\n",
    "    .when((col(\"main.temp\") >= 15) & (col(\"main.temp\") <= 25), \"AgradÃ¡vel\")\n",
    "    .otherwise(\"Quente\")\n",
    ")\n",
    "\n",
    "# ğŸ“Š Exibir os dados com a nova categoria de temperatura\n",
    "print(\"ğŸ“Š Dados categorizados:\")\n",
    "df_categorizado.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f1c31be-ddb0-4bbf-9485-b93962c52684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ Contagem de Cidades por Categoria de Temperatura\n",
    "Agora que categorizamos as temperaturas, vamos **contar quantas cidades pertencem a cada categoria** (`Frio`, `AgradÃ¡vel`, `Quente`).\n",
    "\n",
    "Isso nos permite entender **como a temperatura estÃ¡ distribuÃ­da entre as cidades** e identificar tendÃªncias climÃ¡ticas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c7e798d-34b2-428c-ba96-0253b3c8b6d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Quantidade de cidades distintas por categoria de temperatura:\n+--------------------+------------+\n|temperature_category|total_cities|\n+--------------------+------------+\n|Quente              |11          |\n+--------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ **Contar cidades distintas em cada categoria de temperatura**\n",
    "df_contagem = df_categorizado.groupBy(\"temperature_category\").agg(countDistinct(\"name\").alias(\"total_cities\"))\n",
    "\n",
    "# ğŸ“Š Exibir os resultados ordenados por categoria\n",
    "print(\"ğŸ“Š Quantidade de cidades distintas por categoria de temperatura:\")\n",
    "df_contagem.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6fc1848-5582-47fe-a977-c685fb0fd154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ Ranking das Cidades Mais Quentes\n",
    "Agora, vamos criar um **ranking das cidades com as temperaturas mais altas**, ordenando os dados da **maior para a menor temperatura**.\n",
    "\n",
    "Isso nos ajudarÃ¡ a identificar **quais cidades estÃ£o enfrentando as temperaturas mais elevadas** no momento da anÃ¡lise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62b5ea7a-5f96-4dff-bdef-fa30dd72de4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Top 5 Cidades Mais Quentes:\n+-------+--------------+--------+\n|ranking|name          |max_temp|\n+-------+--------------+--------+\n|1      |Porto Alegre  |30.93   |\n|2      |BrasÃ­lia      |30.51   |\n|3      |Belo Horizonte|30.44   |\n|4      |Rio de Janeiro|29.08   |\n|5      |Fortaleza     |29.07   |\n+-------+--------------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ **Selecionar a maior temperatura registrada para cada cidade**\n",
    "df_ranking = df_categorizado.groupBy(\"name\").agg(\n",
    "    max(\"main.temp\").alias(\"max_temp\")  # Pegando a maior temperatura registrada por cidade\n",
    ")\n",
    "\n",
    "# ğŸ”¹ **Criar a posiÃ§Ã£o no ranking**\n",
    "window_spec = Window.orderBy(col(\"max_temp\").desc())\n",
    "df_ranking = df_ranking.withColumn(\"ranking\", row_number().over(window_spec))\n",
    "\n",
    "# ğŸ“Š Exibir o Top 5 das cidades mais quentes\n",
    "print(\"ğŸ“Š Top 5 Cidades Mais Quentes:\")\n",
    "df_ranking.select(\"ranking\", \"name\", \"max_temp\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71005b4a-1e18-4076-9c12-8692116654a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ CÃ¡lculo da MÃ©dia MÃ³vel da Temperatura\n",
    "Agora, vamos calcular uma **mÃ©dia mÃ³vel da temperatura** para cada cidade, considerando os Ãºltimos **3 registros**.\n",
    "\n",
    "Isso ajudarÃ¡ a suavizar variaÃ§Ãµes e entender **a tendÃªncia de temperatura ao longo do tempo**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc73c722-05cf-40cc-ad0a-515b17989a9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š MÃ©dia MÃ³vel Final por Cidade:\n+--------------+------------------+\n|name          |avg_temp_3_records|\n+--------------+------------------+\n|Belo Horizonte|30.44             |\n|BelÃ©m         |29.02             |\n|BrasÃ­lia      |30.51             |\n|Curitiba      |25.03             |\n|Fortaleza     |28.57             |\n|Manaus        |26.27             |\n|Porto Alegre  |30.73             |\n|Recife        |29.02             |\n|Rio de Janeiro|29.08             |\n|Salvador      |28.98             |\n|SÃ£o Paulo     |25.805            |\n+--------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ Criar um ID incremental para simular timestamps diferentes\n",
    "df_temporal = df_categorizado.withColumn(\"timestamp\", expr(\"current_timestamp() + interval 10 seconds * (monotonically_increasing_id() % 5)\"))\n",
    "\n",
    "# ğŸ”¹ Criar uma janela de tempo para calcular a mÃ©dia mÃ³vel considerando os Ãºltimos 3 registros\n",
    "window_spec = Window.partitionBy(\"name\").orderBy(col(\"timestamp\")).rowsBetween(-2, 0)\n",
    "\n",
    "# ğŸ”¹ Calcular a mÃ©dia mÃ³vel da temperatura\n",
    "df_media_movel = df_temporal.withColumn(\"avg_temp_3_records\", avg(\"main.temp\").over(window_spec))\n",
    "\n",
    "# ğŸ”¹ Selecionar apenas a Ãºltima mÃ©dia mÃ³vel calculada para cada cidade\n",
    "df_final = df_media_movel.groupBy(\"name\").agg(last(\"avg_temp_3_records\").alias(\"avg_temp_3_records\"))\n",
    "\n",
    "# ğŸ“Š Exibir o resultado final (um Ãºnico registro por cidade)\n",
    "print(\"ğŸ“Š MÃ©dia MÃ³vel Final por Cidade:\")\n",
    "df_final.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0236e4d6-bbf4-4210-ab24-d54088a54e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ DiferenÃ§a entre Temperatura Atual e MÃ©dia MÃ³vel\n",
    "Agora, vamos calcular a **diferenÃ§a entre a temperatura mais recente de cada cidade e a mÃ©dia mÃ³vel**.\n",
    "\n",
    "Isso nos ajudarÃ¡ a entender **se a temperatura estÃ¡ subindo ou caindo** em relaÃ§Ã£o Ã  tendÃªncia recente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62db5aee-6e33-4ae7-8fbb-11a08695d89d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š DiferenÃ§a entre Temperatura Atual e MÃ©dia MÃ³vel:\n+--------------+-----------+------------------+-------------------+\n|name          |latest_temp|avg_temp_3_records|temp_variation     |\n+--------------+-----------+------------------+-------------------+\n|Belo Horizonte|30.44      |30.44             |0.0                |\n|BelÃ©m         |29.02      |29.02             |0.0                |\n|BrasÃ­lia      |30.51      |30.51             |0.0                |\n|Curitiba      |25.03      |25.03             |0.0                |\n|Fortaleza     |29.07      |28.57             |0.5                |\n|Manaus        |26.27      |26.27             |0.0                |\n|Porto Alegre  |30.93      |30.73             |0.1999999999999993 |\n|Recife        |29.02      |29.02             |0.0                |\n|Rio de Janeiro|29.08      |29.08             |0.0                |\n|Salvador      |28.98      |28.98             |0.0                |\n|SÃ£o Paulo     |25.89      |25.805            |0.08500000000000085|\n+--------------+-----------+------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ Pegar a temperatura mais recente para cada cidade\n",
    "df_temp_recente = df_temporal.groupBy(\"name\").agg(\n",
    "    max(\"main.temp\").alias(\"latest_temp\")  # Ãšltima temperatura registrada\n",
    ")\n",
    "\n",
    "# ğŸ”¹ Juntar com a mÃ©dia mÃ³vel final\n",
    "df_com_diferenca = df_temp_recente.join(df_final, \"name\", \"inner\") \\\n",
    "    .withColumn(\"temp_variation\", col(\"latest_temp\") - col(\"avg_temp_3_records\"))\n",
    "\n",
    "# ğŸ“Š Exibir os resultados finais\n",
    "print(\"ğŸ“Š DiferenÃ§a entre Temperatura Atual e MÃ©dia MÃ³vel:\")\n",
    "df_com_diferenca.select(\"name\", \"latest_temp\", \"avg_temp_3_records\", \"temp_variation\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6d232cf-d7ec-429c-b0b9-9221e39a5598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ Passo Final: ExportaÃ§Ã£o dos Dados Processados\n",
    "Agora, vamos **salvar os dados finais** para que possam ser usados posteriormente.  \n",
    "Os arquivos serÃ£o exportados nos seguintes formatos:\n",
    "- ğŸ—‚ **Parquet** (`.parquet`) â†’ Compactado e otimizado para Big Data\n",
    "- ğŸ“„ **CSV** (`.csv`) â†’ FÃ¡cil de visualizar e compartilhar\n",
    "- ğŸ“œ **JSON** (`.json`) â†’ Bom para integraÃ§Ã£o com APIs\n",
    "\n",
    "Isso garante que os dados estejam prontos para serem consumidos por outras aplicaÃ§Ãµes e anÃ¡lises futuras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "893f3b74-96a5-417c-816d-757f70e4f7a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dados salvos em Parquet: dbfs:/FileStore/weather_final.parquet\nâœ… Dados salvos em CSV: dbfs:/FileStore/weather_final.csv\nâœ… Dados salvos em JSON: dbfs:/FileStore/weather_final.json\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‚ DiretÃ³rio onde os arquivos serÃ£o salvos\n",
    "output_path_parquet = \"dbfs:/FileStore/weather_final.parquet\"\n",
    "output_path_csv = \"dbfs:/FileStore/weather_final.csv\"\n",
    "output_path_json = \"dbfs:/FileStore/weather_final.json\"\n",
    "\n",
    "# ğŸ—‘ï¸ Deletar arquivos antigos antes de salvar os novos\n",
    "dbutils.fs.rm(output_path_parquet, recurse=True)\n",
    "dbutils.fs.rm(output_path_csv, recurse=True)\n",
    "dbutils.fs.rm(output_path_json, recurse=True)\n",
    "\n",
    "# ğŸ’¾ Salvar os dados finais em Parquet\n",
    "df_com_diferenca.write.mode(\"overwrite\").parquet(output_path_parquet)\n",
    "print(f\"âœ… Dados salvos em Parquet: {output_path_parquet}\")\n",
    "\n",
    "# ğŸ’¾ Salvar os dados finais em CSV\n",
    "df_com_diferenca.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path_csv)\n",
    "print(f\"âœ… Dados salvos em CSV: {output_path_csv}\")\n",
    "\n",
    "# ğŸ’¾ Salvar os dados finais em JSON\n",
    "df_com_diferenca.write.mode(\"overwrite\").json(output_path_json)\n",
    "print(f\"âœ… Dados salvos em JSON: {output_path_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bb7e020-ecf9-4c31-80dc-bb7760c58a10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ğŸ“Œ Deploy do Pipeline no Databricks\n",
    "Agora, vamos configurar a **execuÃ§Ã£o automÃ¡tica** do pipeline, garantindo que os dados sejam processados e salvos sem intervenÃ§Ã£o manual.\n",
    "\n",
    "### **ğŸ“Œ Como funciona?**\n",
    "- Criamos um **Job no Databricks** para rodar automaticamente.\n",
    "- Configuramos um **agendamento** (a cada 1 hora).\n",
    "- O Job roda nosso **Notebook de Pipeline**, garantindo que os dados estejam sempre atualizados.\n",
    "\n",
    "Isso permite **automatizar o processamento**, tornando o pipeline **mais eficiente e escalÃ¡vel**! ğŸš€\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Clima",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
